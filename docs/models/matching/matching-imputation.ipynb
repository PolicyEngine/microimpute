{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Matching Imputation\n",
    "\n",
    "This notebook demonstrates how to use MicroImpute's Matching imputer to impute values using the statistical matching approach. Statistical matching (also known as data fusion or synthetic matching) is a technique used to integrate information from different data sources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How Matching Imputation Works\n",
    "\n",
    "Statistical matching imputation works by finding similar records in a donor dataset and transferring values to a recipient dataset. The key concept is to match records based on common variables present in both datasets.\n",
    "\n",
    "The Matching imputer in MicroImpute:\n",
    "- Uses nearest neighbor distance hot deck matching via R's StatMatch package\n",
    "- Identifies donors with similar characteristics to recipients\n",
    "- Transfers values from donors to recipients based on the similarity of matching variables\n",
    "- Can handle different types of variables including categorical variables\n",
    "- Doesn't make distributional assumptions unlike parametric methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import MicroImpute tools\n",
    "from microimpute.comparisons.data import preprocess_data\n",
    "from microimpute.models import Matching\n",
    "from microimpute.config import QUANTILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the diabetes dataset\n",
    "diabetes = load_diabetes()\n",
    "df = pd.DataFrame(diabetes.data, columns=diabetes.feature_names)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables for the model\n",
    "predictors = [\"age\", \"sex\", \"bmi\", \"bp\"]\n",
    "imputed_variables = [\"s1\"]  # We'll impute 's1' (total serum cholesterol)\n",
    "\n",
    "# Create a subset with only needed columns\n",
    "diabetes_df = df[predictors + imputed_variables]\n",
    "\n",
    "# Display summary statistics\n",
    "diabetes_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test = train_test_split(diabetes_df, test_size=0.3, random_state=42)\n",
    "\n",
    "# Let's see how many records we have in each set\n",
    "print(f\"Training set size: {X_train.shape[0]} records\")\n",
    "print(f\"Testing set size: {X_test.shape[0]} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulating Missing Data\n",
    "\n",
    "For this example, we'll simulate missing data in our test set by removing the values we want to impute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the test set with missing values\n",
    "X_test_missing = X_test.copy()\n",
    "\n",
    "# Store the actual values for later comparison\n",
    "actual_values = X_test_missing[imputed_variables].copy()\n",
    "\n",
    "# Remove the values to be imputed\n",
    "X_test_missing[imputed_variables] = np.nan\n",
    "\n",
    "X_test_missing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Using the Matching Imputer\n",
    "\n",
    "Now we'll train the Matching imputer and use it to impute the missing values in our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Matching imputer\n",
    "matching_imputer = Matching()\n",
    "\n",
    "# Fit the model with our training data\n",
    "# This stores the donor records for later matching\n",
    "matching_imputer.fit(X_train, predictors, imputed_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute values in the test set\n",
    "# This will identify similar donors for each recipient and transfer values\n",
    "imputed_values = matching_imputer.predict(X_test_missing, QUANTILES)\n",
    "\n",
    "# Display the first few imputed values at the median (0.5 quantile)\n",
    "imputed_values[0.5].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Imputation Results\n",
    "\n",
    "Now let's compare the imputed values with the actual values to evaluate the performance of our imputer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract median predictions for evaluation\n",
    "median_predictions = imputed_values[0.5]\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE) for the median predictions\n",
    "mae = np.abs(median_predictions - actual_values).mean()\n",
    "print(f\"Mean Absolute Error: {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatter plot comparing actual vs. imputed values\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(actual_values, median_predictions, alpha=0.5)\n",
    "plt.plot([actual_values.min().min(), actual_values.max().max()], \n",
    "         [actual_values.min().min(), actual_values.max().max()], \n",
    "         'r--')\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Imputed Values')\n",
    "plt.title('Comparison of Actual vs. Imputed Values using Matching')\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examining Quantile Predictions\n",
    "\n",
    "The Matching imputer can also provide predictions at different quantiles, which can be useful for understanding the uncertainty in the imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare predictions at different quantiles for the first 5 records\n",
    "quantiles_to_show = [0.1, 0.25, 0.5, 0.75, 0.9]\n",
    "comparison_df = pd.DataFrame(index=range(5))\n",
    "\n",
    "# Add actual values\n",
    "comparison_df['Actual'] = actual_values.iloc[:5, 0].values\n",
    "\n",
    "# Add quantile predictions\n",
    "for q in quantiles_to_show:\n",
    "    comparison_df[f'Q{int(q*100)}'] = imputed_values[q].iloc[:5, 0].values\n",
    "\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advantages and Limitations of Matching Imputation\n",
    "\n",
    "### Advantages:\n",
    "- Preserves relationships between variables as they exist in the donor dataset\n",
    "- Makes no parametric assumptions about the distribution of the data\n",
    "- Can handle both continuous and categorical variables\n",
    "- Relatively simple to understand conceptually\n",
    "- Generally preserves the marginal distributions of the variables\n",
    "\n",
    "### Limitations:\n",
    "- Requires a rich donor dataset with sufficient coverage\n",
    "- May not perform well if donor and recipient populations differ significantly\n",
    "- Matching quality depends on the selection of matching variables\n",
    "- Limited ability to extrapolate beyond the range of the donor dataset\n",
    "- May struggle with high-dimensional data due to the curse of dimensionality"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
