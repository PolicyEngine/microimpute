{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ordinary Least Squares (OLS) Imputation\n",
    "\n",
    "This notebook demonstrates how to use MicroImpute's OLS imputer to impute values using linear regression. OLS imputation is a parametric approach that assumes a linear relationship between the predictor variables and the variable being imputed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How OLS Imputation Works\n",
    "\n",
    "OLS imputation works by fitting a linear regression model to predict missing values based on other observed variables. The OLS imputer in MicroImpute:\n",
    "\n",
    "- Uses statsmodels OLS to fit a linear regression model\n",
    "- Assumes normally distributed residuals to generate quantile predictions\n",
    "- Predicts different quantiles by adding scaled normal quantiles to the mean prediction\n",
    "- Provides symmetric predictions around the median due to the normal assumption\n",
    "- Is efficient and works well when relationships between variables are approximately linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import MicroImpute tools\n",
    "from microimpute.comparisons.data import preprocess_data\n",
    "from microimpute.models import OLS\n",
    "from microimpute.config import QUANTILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the diabetes dataset\n",
    "diabetes = load_diabetes()\n",
    "df = pd.DataFrame(diabetes.data, columns=diabetes.feature_names)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables for the model\n",
    "predictors = [\"age\", \"sex\", \"bmi\", \"bp\"]\n",
    "imputed_variables = [\"s1\"]  # We'll impute 's1' (total serum cholesterol)\n",
    "\n",
    "# Create a subset with only needed columns\n",
    "diabetes_df = df[predictors + imputed_variables]\n",
    "\n",
    "# Display summary statistics\n",
    "diabetes_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test = train_test_split(diabetes_df, test_size=0.3, random_state=42)\n",
    "\n",
    "# Let's see how many records we have in each set\n",
    "print(f\"Training set size: {X_train.shape[0]} records\")\n",
    "print(f\"Testing set size: {X_test.shape[0]} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulating Missing Data\n",
    "\n",
    "For this example, we'll simulate missing data in our test set by removing the values we want to impute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the test set with missing values\n",
    "X_test_missing = X_test.copy()\n",
    "\n",
    "# Store the actual values for later comparison\n",
    "actual_values = X_test_missing[imputed_variables].copy()\n",
    "\n",
    "# Remove the values to be imputed\n",
    "X_test_missing[imputed_variables] = np.nan\n",
    "\n",
    "X_test_missing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Using the OLS Imputer\n",
    "\n",
    "Now we'll train the OLS imputer and use it to impute the missing values in our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the OLS imputer\n",
    "ols_imputer = OLS()\n",
    "\n",
    "# Fit the model with our training data\n",
    "# This trains a linear regression model\n",
    "ols_imputer.fit(X_train, predictors, imputed_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute values in the test set\n",
    "# This uses the trained OLS model to predict missing values\n",
    "imputed_values = ols_imputer.predict(X_test_missing, QUANTILES)\n",
    "\n",
    "# Display the first few imputed values at the median (0.5 quantile)\n",
    "imputed_values[0.5].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Imputation Results\n",
    "\n",
    "Now let's compare the imputed values with the actual values to evaluate the performance of our imputer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract median predictions for evaluation\n",
    "median_predictions = imputed_values[0.5]\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE) for the median predictions\n",
    "mae = np.abs(median_predictions - actual_values).mean()\n",
    "print(f\"Mean Absolute Error: {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatter plot comparing actual vs. imputed values\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(actual_values, median_predictions, alpha=0.5)\n",
    "plt.plot([actual_values.min().min(), actual_values.max().max()], \n",
    "         [actual_values.min().min(), actual_values.max().max()], \n",
    "         'r--')\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Imputed Values')\n",
    "plt.title('Comparison of Actual vs. Imputed Values using OLS')\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examining Quantile Predictions\n",
    "\n",
    "The OLS imputer generates quantile predictions based on the normal distribution assumption, which can help understand prediction uncertainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare predictions at different quantiles for the first 5 records\n",
    "quantiles_to_show = [0.1, 0.25, 0.5, 0.75, 0.9]\n",
    "comparison_df = pd.DataFrame(index=range(5))\n",
    "\n",
    "# Add actual values\n",
    "comparison_df['Actual'] = actual_values.iloc[:5, 0].values\n",
    "\n",
    "# Add quantile predictions\n",
    "for q in quantiles_to_show:\n",
    "    comparison_df[f'Q{int(q*100)}'] = imputed_values[q].iloc[:5, 0].values\n",
    "\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the OLS Model\n",
    "\n",
    "We can examine the OLS model coefficients to understand the relationship between predictor variables and the imputed variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the underlying model for s1\n",
    "ols_model = ols_imputer.models[imputed_variables[0]]\n",
    "\n",
    "# Print model summary\n",
    "print(ols_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advantages and Limitations of OLS Imputation\n",
    "\n",
    "### Advantages:\n",
    "- Simple and interpretable model\n",
    "- Computationally efficient\n",
    "- Works well when relationships are approximately linear\n",
    "- Provides a confidence interval for predictions\n",
    "- Coefficients are directly interpretable\n",
    "\n",
    "### Limitations:\n",
    "- Assumes linear relationships between variables\n",
    "- Assumes normally distributed residuals\n",
    "- May not capture complex interactions\n",
    "- Predictions are symmetric around the median\n",
    "- Sensitive to outliers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
