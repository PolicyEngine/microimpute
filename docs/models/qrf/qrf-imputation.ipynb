{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantile Random Forest (QRF) Imputation\n",
    "\n",
    "This notebook demonstrates how to use MicroImpute's QRF imputer to impute values using Quantile Random Forests. QRF is a powerful machine learning technique that extends traditional random forests to predict the entire conditional distribution of a target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How QRF Imputation Works\n",
    "\n",
    "Quantile Random Forest imputation builds a non-parametric machine learning model that can predict any quantile of the distribution of missing values. The QRF imputer in MicroImpute:\n",
    "\n",
    "- Uses a random forest model to predict quantiles directly\n",
    "- Captures complex, non-linear relationships between variables\n",
    "- Handles categorical features through one-hot encoding\n",
    "- Models heteroskedasticity (where variance is not constant across the distribution)\n",
    "- Can represent multimodal and skewed distributions\n",
    "- Provides more flexible/accurate quantile predictions than parametric methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import MicroImpute tools\n",
    "from microimpute.comparisons.data import preprocess_data\n",
    "from microimpute.models import QRF\n",
    "from microimpute.config import QUANTILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the diabetes dataset\n",
    "diabetes = load_diabetes()\n",
    "df = pd.DataFrame(diabetes.data, columns=diabetes.feature_names)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables for the model\n",
    "predictors = [\"age\", \"sex\", \"bmi\", \"bp\"]\n",
    "imputed_variables = [\"s1\"]  # We'll impute 's1' (total serum cholesterol)\n",
    "\n",
    "# Create a subset with only needed columns\n",
    "diabetes_df = df[predictors + imputed_variables]\n",
    "\n",
    "# Display summary statistics\n",
    "diabetes_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test = train_test_split(diabetes_df, test_size=0.3, random_state=42)\n",
    "\n",
    "# Let's see how many records we have in each set\n",
    "print(f\"Training set size: {X_train.shape[0]} records\")\n",
    "print(f\"Testing set size: {X_test.shape[0]} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulating Missing Data\n",
    "\n",
    "For this example, we'll simulate missing data in our test set by removing the values we want to impute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the test set with missing values\n",
    "X_test_missing = X_test.copy()\n",
    "\n",
    "# Store the actual values for later comparison\n",
    "actual_values = X_test_missing[imputed_variables].copy()\n",
    "\n",
    "# Remove the values to be imputed\n",
    "X_test_missing[imputed_variables] = np.nan\n",
    "\n",
    "X_test_missing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Using the QRF Imputer\n",
    "\n",
    "Now we'll train the QRF imputer and use it to impute the missing values in our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the QRF imputer with some custom parameters\n",
    "# You can customize the random forest by passing additional parameters\n",
    "qrf_imputer = QRF()\n",
    "\n",
    "# Fit the model with our training data\n",
    "# This trains a quantile random forest model\n",
    "qrf_imputer.fit(X_train, predictors, imputed_variables, n_estimators=100, min_samples_leaf=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute values in the test set\n",
    "# This uses the trained QRF model to predict missing values at specified quantiles\n",
    "imputed_values = qrf_imputer.predict(X_test_missing, QUANTILES)\n",
    "\n",
    "# Display the first few imputed values at the median (0.5 quantile)\n",
    "imputed_values[0.5].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Imputation Results\n",
    "\n",
    "Now let's compare the imputed values with the actual values to evaluate the performance of our imputer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract median predictions for evaluation\n",
    "median_predictions = imputed_values[0.5]\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE) for the median predictions\n",
    "mae = np.abs(median_predictions - actual_values).mean()\n",
    "print(f\"Mean Absolute Error: {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatter plot comparing actual vs. imputed values\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(actual_values, median_predictions, alpha=0.5)\n",
    "plt.plot([actual_values.min().min(), actual_values.max().max()], \n",
    "         [actual_values.min().min(), actual_values.max().max()], \n",
    "         'r--')\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Imputed Values')\n",
    "plt.title('Comparison of Actual vs. Imputed Values using QRF')\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examining Quantile Predictions\n",
    "\n",
    "QRF provides predictions at different quantiles, allowing us to capture the entire conditional distribution of the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare predictions at different quantiles for the first 5 records\n",
    "quantiles_to_show = [0.1, 0.25, 0.5, 0.75, 0.9]\n",
    "comparison_df = pd.DataFrame(index=range(5))\n",
    "\n",
    "# Add actual values\n",
    "comparison_df['Actual'] = actual_values.iloc[:5, 0].values\n",
    "\n",
    "# Add quantile predictions\n",
    "for q in quantiles_to_show:\n",
    "    comparison_df[f'Q{int(q*100)}'] = imputed_values[q].iloc[:5, 0].values\n",
    "\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Prediction Intervals\n",
    "\n",
    "One of the advantages of QRF is that it can provide prediction intervals, which can help us understand the uncertainty in our imputed values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a prediction interval plot for the first 10 records\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Number of records to plot\n",
    "n_records = 10\n",
    "\n",
    "# X-axis positions\n",
    "x = np.arange(n_records)\n",
    "\n",
    "# Plot actual values\n",
    "plt.scatter(x, actual_values.iloc[:n_records, 0], color='black', label='Actual', zorder=3)\n",
    "\n",
    "# Plot median predictions\n",
    "plt.scatter(x, imputed_values[0.5].iloc[:n_records, 0], color='red', label='Median (Q50)', zorder=3)\n",
    "\n",
    "# Plot 50% prediction interval (Q25 to Q75)\n",
    "plt.fill_between(x, \n",
    "                 imputed_values[0.25].iloc[:n_records, 0],\n",
    "                 imputed_values[0.75].iloc[:n_records, 0],\n",
    "                 alpha=0.3, color='blue', label='50% PI (Q25-Q75)')\n",
    "\n",
    "# Plot 80% prediction interval (Q10 to Q90)\n",
    "plt.fill_between(x, \n",
    "                 imputed_values[0.1].iloc[:n_records, 0],\n",
    "                 imputed_values[0.9].iloc[:n_records, 0],\n",
    "                 alpha=0.15, color='blue', label='80% PI (Q10-Q90)')\n",
    "\n",
    "plt.xlabel('Record Index')\n",
    "plt.ylabel('Value')\n",
    "plt.title('QRF Imputation Prediction Intervals')\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advantages and Limitations of QRF Imputation\n",
    "\n",
    "### Advantages:\n",
    "- Captures non-linear relationships and interactions between variables\n",
    "- Models heteroskedasticity (variance that changes across the distribution)\n",
    "- Handles categorical variables effectively\n",
    "- Robust to outliers and noisy data\n",
    "- Can represent complex distributions including multimodality and skewness\n",
    "- No distributional assumptions about residuals\n",
    "\n",
    "### Limitations:\n",
    "- More computationally intensive than parametric methods\n",
    "- Requires more data to train effectively\n",
    "- Less interpretable than linear models\n",
    "- May overfit with small sample sizes if not properly tuned\n",
    "- Prediction time increases with the number of trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning the QRF Model\n",
    "\n",
    "The QRF imputer supports various parameters that can be adjusted to improve performance. Here are some of the key parameters you might want to tune:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of creating a QRF imputer with custom parameters\n",
    "tuned_qrf_imputer = QRF()\n",
    "\n",
    "# Fit with custom parameters\n",
    "tuned_qrf_imputer.fit(\n",
    "    X_train, \n",
    "    predictors, \n",
    "    imputed_variables,\n",
    "    n_estimators=200,            # Number of trees in the forest\n",
    "    min_samples_leaf=3,          # Minimum samples required at a leaf node\n",
    "    max_features='sqrt',         # Number of features to consider for best split\n",
    "    bootstrap=True,              # Whether to use bootstrap samples\n",
    "    random_state=42,             # Random seed for reproducibility\n",
    "    n_jobs=-1                    # Use all available cores\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
